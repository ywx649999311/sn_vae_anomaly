{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import jit\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>passband</th>\n",
       "      <th>mjd</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>59577.000000</td>\n",
       "      <td>0.125404</td>\n",
       "      <td>-0.242782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>59592.521127</td>\n",
       "      <td>0.243606</td>\n",
       "      <td>-0.167201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id  passband           mjd      flux  flux_norm\n",
       "0         13         0  59577.000000  0.125404  -0.242782\n",
       "1         13         0  59592.521127  0.243606  -0.167201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read lc\n",
    "lc = pd.read_parquet('data/lc1.parquet')\n",
    "lc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from flax import linen as nn\n",
    "# from flax import optim\n",
    "import optax\n",
    "\n",
    "class Encoder(nn.Module):\n",
    " latents: int\n",
    "\n",
    " @nn.compact\n",
    " def __call__(self, x):\n",
    "   x = nn.Dense(500, name='fc1')(x)\n",
    "   x = nn.relu(x)\n",
    "   mean_x = nn.Dense(self.latents, name='fc2_mean')(x)\n",
    "   logvar_x = nn.Dense(self.latents, name='fc2_logvar')(x)\n",
    "   return mean_x, logvar_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    " @nn.compact\n",
    " def __call__(self, z):\n",
    "   z = nn.Dense(500, name='fc1')(z)\n",
    "   z = nn.relu(z)\n",
    "   z = nn.Dense(784, name='fc2')(z)\n",
    "   return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    " latents: int = 20\n",
    "\n",
    " def setup(self):\n",
    "   self.encoder = Encoder(self.latents)\n",
    "   self.decoder = Decoder()\n",
    "\n",
    " def __call__(self, x, z_rng):\n",
    "   mean, logvar = self.encoder(x)\n",
    "   z = reparameterize(z_rng, mean, logvar)\n",
    "   recon_x = self.decoder(z)\n",
    "   return recon_x, mean, logvar\n",
    "\n",
    "def reparameterize(rng, mean, logvar):\n",
    " std = jnp.exp(0.5 * logvar)\n",
    " eps = random.normal(rng, logvar.shape)\n",
    " return mean + eps * std\n",
    "\n",
    "def model():\n",
    " return VAE(latents=LATENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def kl_divergence(mean, logvar):\n",
    " return -0.5 * jnp.sum(1 + logvar - jnp.square(mean) - jnp.exp(logvar))\n",
    "\n",
    "@jax.vmap\n",
    "def binary_cross_entropy_with_logits(logits, labels):\n",
    " logits = nn.log_sigmoid(logits)\n",
    " return -jnp.sum(labels * logits + (1. - labels) * jnp.log(-jnp.expm1(logits)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 11:46:12.056960: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 104.68 MiB (download: 104.68 MiB, generated: Unknown size, total: 104.68 MiB) to /Users/weixiang/tensorflow_datasets/binarized_mnist/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weixiang/mambaforge/envs/eztao-jax/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dl Size...: 100%|██████████| 102/102 [00:07<00:00, 12.92 MiB/s]]\n",
      "Dl Completed...: 100%|██████████| 3/3 [00:07<00:00,  2.63s/ url]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset binarized_mnist downloaded and prepared to /Users/weixiang/tensorflow_datasets/binarized_mnist/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "\n",
    "def prepare_image(x):\n",
    " x = tf.cast(x['image'], tf.float32)\n",
    " x = tf.reshape(x, (-1,))\n",
    " return x\n",
    "\n",
    "ds_builder = tfds.builder('binarized_mnist')\n",
    "ds_builder.download_and_prepare()\n",
    "train_ds = ds_builder.as_dataset(split=tfds.Split.TRAIN)\n",
    "train_ds = train_ds.map(prepare_image)\n",
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.shuffle(50000)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = iter(tfds.as_numpy(train_ds))\n",
    "\n",
    "test_ds = ds_builder.as_dataset(split=tfds.Split.TEST)\n",
    "test_ds = test_ds.map(prepare_image).batch(10000)\n",
    "test_ds = np.array(list(test_ds)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Gradient only defined for scalar-output functions. Output was (Array(594.6463, dtype=float32), Array([[ 0.61815804, -0.41764262,  0.70575905, ...,  0.04700679,\n        -0.5066801 ,  0.95056593],\n       [ 0.45177734, -0.86700225,  0.54775393, ..., -0.04440165,\n        -0.42860085, -0.40191096],\n       [ 0.2963302 , -0.89565736,  1.5676657 , ..., -0.01574579,\n        -0.7308027 ,  0.44394773],\n       ...,\n       [ 0.13361356, -0.9049638 ,  1.3185327 , ..., -0.23299226,\n        -0.6748854 , -0.06925374],\n       [ 0.41827285, -0.54509956,  0.6054094 , ...,  0.13635437,\n        -0.5661339 ,  0.573411  ],\n       [ 0.5138072 , -0.25701073,  0.07712258, ..., -0.00742109,\n        -0.32133615,  0.01739584]], dtype=float32)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/eztao-jax/lib/python3.12/site-packages/jax/_src/core.py:1463\u001b[0m, in \u001b[0;36mget_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1463\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_aval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/eztao-jax/lib/python3.12/site-packages/jax/_src/core.py:1455\u001b[0m, in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_aval(x\u001b[38;5;241m.\u001b[39m__jax_array__())\n\u001b[0;32m-> 1455\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid JAX \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1456\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Value (Array(594.6463, dtype=float32), Array([[ 0.61815804, -0.41764262,  0.70575905, ...,  0.04700679,\n        -0.5066801 ,  0.95056593],\n       [ 0.45177734, -0.86700225,  0.54775393, ..., -0.04440165,\n        -0.42860085, -0.40191096],\n       [ 0.2963302 , -0.89565736,  1.5676657 , ..., -0.01574579,\n        -0.7308027 ,  0.44394773],\n       ...,\n       [ 0.13361356, -0.9049638 ,  1.3185327 , ..., -0.23299226,\n        -0.6748854 , -0.06925374],\n       [ 0.41827285, -0.54509956,  0.6054094 , ...,  0.13635437,\n        -0.5661339 ,  0.573411  ],\n       [ 0.5138072 , -0.25701073,  0.07712258, ..., -0.00742109,\n        -0.32133615,  0.01739584]], dtype=float32)) with type <class 'tuple'> is not a valid JAX type",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     loss \u001b[38;5;241m=\u001b[39m bce_loss \u001b[38;5;241m+\u001b[39m kld_loss\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, recon_x\n\u001b[0;32m---> 34\u001b[0m grad, _ \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m updates, opt_state \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mupdate(grad, opt_state, params)\n\u001b[1;32m     36\u001b[0m params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/eztao-jax/lib/python3.12/site-packages/jax/_src/api.py:716\u001b[0m, in \u001b[0;36m_check_scalar\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    714\u001b[0m   aval \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mget_aval(x)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 716\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(aval, ShapedArray):\n",
      "\u001b[0;31mTypeError\u001b[0m: Gradient only defined for scalar-output functions. Output was (Array(594.6463, dtype=float32), Array([[ 0.61815804, -0.41764262,  0.70575905, ...,  0.04700679,\n        -0.5066801 ,  0.95056593],\n       [ 0.45177734, -0.86700225,  0.54775393, ..., -0.04440165,\n        -0.42860085, -0.40191096],\n       [ 0.2963302 , -0.89565736,  1.5676657 , ..., -0.01574579,\n        -0.7308027 ,  0.44394773],\n       ...,\n       [ 0.13361356, -0.9049638 ,  1.3185327 , ..., -0.23299226,\n        -0.6748854 , -0.06925374],\n       [ 0.41827285, -0.54509956,  0.6054094 , ...,  0.13635437,\n        -0.5661339 ,  0.573411  ],\n       [ 0.5138072 , -0.25701073,  0.07712258, ..., -0.00742109,\n        -0.32133615,  0.01739584]], dtype=float32))."
     ]
    }
   ],
   "source": [
    "rng = random.PRNGKey(0)\n",
    "rng, key = random.split(rng)\n",
    "BATCH_SIZE = 10000\n",
    "LEARNING_RATE = jnp.array(0.3)\n",
    "LATENTS = jnp.array(4)\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "init_data = jnp.ones((BATCH_SIZE, 784), jnp.float32)\n",
    "params = model().init(key, init_data, rng)['params']\n",
    "\n",
    "solver = optax.adam(learning_rate=LEARNING_RATE)\n",
    "opt_state = solver.init(params)\n",
    "# optimizer = jax.device_put(optimizer)\n",
    "\n",
    "rng, z_key, eval_rng = random.split(rng, 3)\n",
    "z = random.normal(z_key, (64, LATENTS))\n",
    "\n",
    "steps_per_epoch = 50000 // BATCH_SIZE\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  for _ in range(steps_per_epoch):\n",
    "    batch = jnp.array(next(train_ds))\n",
    "    rng, key = random.split(rng)\n",
    "\n",
    "    def loss_fn(params):\n",
    "        recon_x, mean, logvar = model().apply({'params': params}, batch, key)\n",
    "\n",
    "        bce_loss = binary_cross_entropy_with_logits(recon_x, batch).mean()\n",
    "        kld_loss = kl_divergence(mean, logvar).mean()\n",
    "        loss = bce_loss + kld_loss\n",
    "        return loss, recon_x\n",
    "\n",
    "    grad, _ = jax.grad(loss_fn)(params)\n",
    "    updates, opt_state = solver.update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eztao-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
